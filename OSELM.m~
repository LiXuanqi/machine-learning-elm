clc;
clear;
%%%%%%初始参数设置
NumberofHiddenNeurons = 20;    %隐层神经元数
N0 = 75;                        %用于初始化阶段的样本数量
Block = 1;                      %在线学习 每步的数据量
%%%%%%载入training set.
train_data = load('housing.txt');
T = train_data(:,14);                   %训练集的第14列为输出
P = train_data(:,1:13);

clear train_data;

%%%%%载入测试集，有什么用

NumberofTrainingData = size(P,1);
NumberofInputNeurons = size(P,2);

%%%%%%%training set 预处理 有啥用
temp_T = zeros(1,NumberofTrainingData);

T = temp_T * 2 - 1;                      %涵义？
%%%%% 初始化阶段
P0 = P(1:N0,:);           %取前N0行数据
T0 = T(1:N0,:);
%%%%%%%随机生成输入权重InputWeight(w_i)和偏置 BiasofHiddenNeurons(b_i)
InputWeight = rand(NumberofHiddenNeurons,NumberofInputNeurons) * 2 - 1;

BiasofHiddenNeurons = rand(1,NumberofHiddenNeurons);    %不同激活函数偏置选择不同

H0 = RBFun(P0,InputWeight,BiasofHiddenNeurons);    %RBF激活函数

M = pinv(H0' * H0);      %求K0的广义逆
beta = pinv(H0) * T0;     %????什么含义-计算输出权重

clear P0 T0 H0;
%%%%%%%%%% 在线学习阶段
for n = N0 : Block : NumberofTrainingData
    if (n + Block - 1) > NumberofTraingData
        Pn = P(n:NumberofTrainingData,:);
        Tn = T(NumberofTrainingData,:);
        Block = size(Pn,1);
        clear V;
    else
        Pn = P(n:(n+Block-1),:);
        Tn = T(n:(n+Block-1),:);
    end
    H = RBFun(Pn,InputWeight,BiasofHiddenNeurons);
    
    M = M - M * H' * (eye(Block) + H * M * H')^(-1) * H * M; %公式哪里来的
    beta = beta + M * H' * (Tn - H * beta);   %beta的迭代公式

end
clear Pn Tn H M;

HTrain = RBFun(P,InputWeight,BiasofHiddenNeurons);

Y = H
%%%%%% 计算训练准确度
Y = (H' * OutputWeight)';
TrainingAccuracy = sqrt(mse(T - Y))      %计算RMSE

